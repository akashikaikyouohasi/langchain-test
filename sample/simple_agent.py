"""
ç°¡æ˜“ç‰ˆ: Human-in-the-Loopä»˜ãã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

ã‚ˆã‚Šç°¡å˜ã«ç†è§£ã§ãã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã™ã€‚
"""

import os
from typing import Annotated, Sequence, TypedDict
from pydantic import BaseModel, Field

from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.tools import tool
from langchain_aws import ChatBedrock

from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode


# ========== ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ„ãƒ¼ãƒ« ==========

@tool
def add_numbers(a: float, b: float) -> float:
    """2ã¤ã®æ•°ã‚’è¶³ã—ç®—ã—ã¾ã™"""
    return a + b


@tool
def multiply_numbers(a: float, b: float) -> float:
    """2ã¤ã®æ•°ã‚’æ›ã‘ç®—ã—ã¾ã™"""
    return a * b


tools = [add_numbers, multiply_numbers]


# ========== æ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ› ==========

class CalculationResult(BaseModel):
    """è¨ˆç®—çµæœã®æ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›"""
    question: str = Field(description="å…ƒã®è³ªå•")
    steps: list[str] = Field(description="å®Ÿè¡Œã—ãŸã‚¹ãƒ†ãƒƒãƒ—")
    final_result: str = Field(description="æœ€çµ‚çµæœ")


# ========== çŠ¶æ…‹ ==========

class State(TypedDict):
    messages: Annotated[Sequence[BaseMessage], lambda x, y: x + y]
    approved: bool


# ========== ãƒãƒ¼ãƒ‰ ==========

def agent_node(state: State):
    """ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ: æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ±ºå®š"""
    llm = ChatBedrock(
        model_id=os.getenv("AWS_BEDROCK_MODEL", "anthropic.claude-3-5-sonnet-20241022-v2:0"),
        model_kwargs={"temperature": 0}
    )
    llm_with_tools = llm.bind_tools(tools)
    response = llm_with_tools.invoke(state["messages"])
    return {"messages": [response]}


def human_approval_node(state: State):
    """äººé–“ã®æ‰¿èªã‚’æ±‚ã‚ã‚‹"""
    last_message = state["messages"][-1]
    
    print("\n" + "="*50)
    print("ğŸ¤” æ‰¿èªãŒå¿…è¦ã§ã™")
    print("="*50)
    
    if hasattr(last_message, "tool_calls"):
        for tc in last_message.tool_calls:
            print(f"ãƒ„ãƒ¼ãƒ«: {tc['name']}")
            print(f"å¼•æ•°: {tc['args']}")
    
    approval = input("\næ‰¿èªã—ã¾ã™ã‹ï¼Ÿ (y/n) > ").strip().lower()
    
    return {"approved": approval in ["y", "yes"]}


def finalize_node(state: State):
    """æœ€çµ‚çš„ãªæ§‹é€ åŒ–å‡ºåŠ›ã‚’ç”Ÿæˆ"""
    llm = ChatBedrock(
        model_id=os.getenv("AWS_BEDROCK_MODEL", "anthropic.claude-3-5-sonnet-20241022-v2:0"),
        model_kwargs={"temperature": 0}
    )
    structured_llm = llm.with_structured_output(CalculationResult)
    
    result = structured_llm.invoke([
        HumanMessage(content="ä¼šè©±å±¥æ­´ã‹ã‚‰è¨ˆç®—çµæœã‚’ã¾ã¨ã‚ã¦ãã ã•ã„"),
        *state["messages"]
    ])
    
    print("\n" + "="*50)
    print("âœ… æœ€çµ‚çµæœï¼ˆæ§‹é€ åŒ–ï¼‰")
    print("="*50)
    print(f"è³ªå•: {result.question}")
    print(f"\nã‚¹ãƒ†ãƒƒãƒ—:")
    for i, step in enumerate(result.steps, 1):
        print(f"  {i}. {step}")
    print(f"\næœ€çµ‚çµæœ: {result.final_result}")
    
    return {"messages": [AIMessage(content="å®Œäº†")]}


# ========== ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° ==========

def should_continue(state: State):
    """æ¬¡ã®ãƒãƒ¼ãƒ‰ã‚’æ±ºå®š"""
    last_message = state["messages"][-1]
    
    # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒã‚ã‚‹ã‹ç¢ºèª
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "human_approval"
    
    return "finalize"


def after_approval(state: State):
    """æ‰¿èªå¾Œã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°"""
    if state.get("approved", False):
        return "tools"
    else:
        return "agent"


# ========== ã‚°ãƒ©ãƒ•æ§‹ç¯‰ ==========

def create_simple_graph():
    """ã‚·ãƒ³ãƒ—ãƒ«ãªã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
    workflow = StateGraph(State)
    
    # ãƒãƒ¼ãƒ‰è¿½åŠ 
    workflow.add_node("agent", agent_node)
    workflow.add_node("human_approval", human_approval_node)
    workflow.add_node("tools", ToolNode(tools))
    workflow.add_node("finalize", finalize_node)
    
    # ãƒ•ãƒ­ãƒ¼è¨­å®š
    workflow.set_entry_point("agent")
    
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "human_approval": "human_approval",
            "finalize": "finalize"
        }
    )
    
    workflow.add_conditional_edges(
        "human_approval",
        after_approval,
        {
            "tools": "tools",
            "agent": "agent"
        }
    )
    
    workflow.add_edge("tools", "agent")
    workflow.add_edge("finalize", END)
    
    return workflow.compile()


# ========== ãƒ¡ã‚¤ãƒ³ ==========

def main():
    print("ã‚·ãƒ³ãƒ—ãƒ«ãª Human-in-the-Loop ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
    print("="*50)
    
    app = create_simple_graph()
    
    # ä¾‹: 10 + 5 ã‚’è¨ˆç®—ã•ã›ã‚‹
    question = "10 + 5 ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„"
    print(f"\nè³ªå•: {question}\n")
    
    initial_state = {
        "messages": [HumanMessage(content=question)],
        "approved": False
    }
    
    for output in app.stream(initial_state):
        pass  # ãƒãƒ¼ãƒ‰ãŒé€²ã‚€ãŸã³ã«å‡¦ç†


if __name__ == "__main__":
    from dotenv import load_dotenv
    
    load_dotenv()
    
    if not os.getenv("AWS_BEDROCK_MODEL"):
        print("âš ï¸  AWS Bedrockã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        print(".envãƒ•ã‚¡ã‚¤ãƒ«ã§AWS_BEDROCK_MODELã‚’è¨­å®šã™ã‚‹ã‹ã€")
        print("AWS CLIã§èªè¨¼æƒ…å ±ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    else:
        main()
